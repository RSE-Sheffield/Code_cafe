{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLD `pandas` material\n",
    "\n",
    "This is designed to be a self-directed study session where you work through the material at your own pace. If you are at a Code Cafe event, instructors will be on hand to help you.\n",
    "\n",
    "If you haven't done so already please read through the **[Introduction](./00-Introduction.ipynb)** to this course, which covers:\n",
    "\n",
    "1. **What Python is** and **why it is of interest**;\n",
    "1. **Learning outcomes** for the course; \n",
    "1. The course **structure** and **support facilities**;\n",
    "1. An introduction to **Jupyter Notebooks**;\n",
    "1. Information on course **exercises**.\n",
    "\n",
    "This lesson covers:\n",
    "\n",
    "<!-- * [Lesson setup code](#Lesson-setup-code) -->\n",
    "* loading data using pandas\n",
    "* [Plotting data](#Plotting-data)\n",
    "* [Packages](#Packages)\n",
    "* [The current working directory](#The-current-working-directory)\n",
    "* [Importing your own data](#Importing-your-own-data)\n",
    "* [Scripts](#Scripts)\n",
    "* [Further reading and next steps](#Further-reading-and-next-steps)\n",
    "* [Getting help NOTES](#Getting-help-NOTES)\n",
    "* [References](#References)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson setup code\n",
    "\n",
    "Run the following Notebook cell *every time* you load this lesson (*but do not edit it*).  Don't be concerned with what this code does at this stage. \n",
    "\n",
    "**TODO: ENSURE NUMPY ALREADY INSTALLED AND AVAILABLE BY THIS POINT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "____ = 0\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy.testing import assert_almost_equal, assert_array_equal\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MISSING SOME TEXT HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../seaborn-data/iris.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we loaded the data from the CSV into a `pandas` **`DataFrame`**, which is a table of data plus a **label** for each row and column.\n",
    "\n",
    "How big is this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that it has 150 rows (and 5 columns) we might not want to view it all at once but instead might just want to see the first few rows:\n",
    "\n",
    "#### TODO: explain that here we have a method of a DataFrame, not a function of a package (although both are expressed in the form `foo.bar`)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now see that each row corresponds to a flower sample and each column to a flower attribute.  Note the names above each column and index values to the left of each row.  Here those index values were not present in the raw data but were automaticaly added when we imported the CSV file.\n",
    "\n",
    "#### TODO: Discuss dtypes?\n",
    "\n",
    "We might also want to view a statistical summary of the dataset to learn of the mean and variance of each flower attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here `std` is the standard deviation and `25%` `50%` and `75%` are [percentiles](https://en.wikipedia.org/wiki/Percentile) of the data.\n",
    "Also, note that the summary is only of the columns that contain numerical data.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to extract just one column then we can wrap the column in single quotes and square brackets then append this to to the DataFrame name.  For example, we can calculate the median sepal length like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['sepal_length'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many unique species do we have in our dataset?\n",
    "\n",
    "#### TODO: here `unique` return a numpy array of objects - explain 'noisy' output from Notebook cell?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['species'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or more concisely:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['species'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting data\n",
    "\n",
    "#### TODO: REWRITE SECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: DECIDE ON PLOTTING APPROACH\n",
    "\n",
    "#### 1. INVOLVES LOOP + BLOCK (INDENTING), MULTIPLE ASSIGNMENT, GROUPBY.  +ve: FAIRLY COMPACT FORM.  AUTOMATIC TITLING AND AXIS LABELLING IS NICE.  -ve: POOR PREPARATION FOR PLOTTING USING NUMPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "for species_name, species_specific_df in df.groupby('species'):\n",
    "    species_specific_df.plot(kind='scatter', x='petal_length', y='petal_width', \n",
    "                             title=species_name);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"n\">OR</p>\n",
    "\n",
    "<p class=\"n\">2. Involves manual figure creation and indexing by boolean series.  +ve: transferrable to plotting with numpy; -ve: more verbose and manual</p>\n",
    "\n",
    "#### TODO: Point out that using comments here and note the value in documenting code</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for each distinct species in our dataset\n",
    "for species in df['species'].unique():\n",
    "    # Isolate all samples of just that species and store the result in a new DataFrame\n",
    "    df_for_species = df[df['species'] == species]\n",
    "    \n",
    "    # Create a blank figure\n",
    "    plt.figure()\n",
    "    \n",
    "    # Create a scatter plot for petal length against width for the current species only\n",
    "    plt.scatter(df_for_species['petal_length'], df_for_species['petal_width'])\n",
    "    \n",
    "    # Add a species-specific title\n",
    "    plt.title(species)\n",
    "    \n",
    "    # Add x and y axis labels\n",
    "    plt.xlabel('Petal length')\n",
    "    plt.ylabel('Petal width')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"n\">or</p>\n",
    "\n",
    "<p class=\"n\">3. seaborn.  How pandas specific?  Better to get aquainted with matplotlib rather than mask away all the complexity?  Nice to have all data on one plot though</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "g = sns.FacetGrid(data=df, hue='species', size=6)\n",
    "g.map(plt.scatter, 'petal_width', 'petal_length')\n",
    "g.add_legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"n\">or</p>\n",
    "\n",
    "<p class=\"n\">4. Another approach with seaborn.  Same points apply</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.lmplot('petal_width', 'petal_length', data=df, hue='species', fit_reg=False, size=6);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: Anscome's quartet\n",
    "\n",
    "Try summarising and plotting a different dataset using the commands you've learned.  The dataset to investigate is [Anscombe's quartet](https://en.wikipedia.org/wiki/Anscombe%27s_quartet), the data for which can be found in the CSV file `../seaborn-data/anscombe.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages\n",
    "\n",
    "#### TODO: REWRITE OR JUST REMOVE SECTION.</p>\n",
    "\n",
    "R has many functions built in but there are over [8000 freely available add-on packages](https://cran.r-project.org/web/packages/) that provide thousands more functions. Once you know the name of a package, you call install it very easily.\n",
    "\n",
    "For example, a package called [ggplot2](http://ggplot2.org/) is widely used to create high quality graphics.  To install ggplot2:\n",
    "\n",
    "    install.packages(\"ggplot2\")\n",
    "\n",
    "We make all of the `ggplot2` functions available to our R session with the `library` command\n",
    "\n",
    "    library(ggplot2)\n",
    "\n",
    "Among other things, this makes the [qplot](http://docs.ggplot2.org/0.9.3/qplot.html) function available to us. We can use this as an alternative to the basic `plot` command described above\n",
    "\n",
    "    qplot(iris$Petal.Length, iris$Petal.Width,col=iris$Species)\n",
    "\n",
    "Alternatively, we can save ourselves typing `iris$` a lot by telling `qplot` that the data we are referring to is the iris data\n",
    "\n",
    "    qplot(data=iris,Petal.Length, Petal.Width,col=Species)\n",
    "\n",
    "To get help about the functionality in the ggplot2 package:\n",
    "\n",
    "    help(package=ggplot2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise (Packages)\n",
    "\n",
    "#### TODO: REWRITE/REPLACE.  NB can't install new packages on SageMathCloud</p>\n",
    "\n",
    "A very popular R package is [MASS](https://cran.r-project.org/web/packages/MASS/index.html) which was created to support the book [Modern Applied Statistics with S](http://www.springer.com/gb/book/9780387954578). This contains many more classic data sets which can be used to develop your R skills.\n",
    "\n",
    "1. Install the MASS package on your machine.\n",
    "2. Explore the MASS package's documentation and find a dataset that interests you.\n",
    "3. Load the MASS library into your R session.\n",
    "4. Take a look at the dataset you chose in part (2) using what you've learned so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The current working directory\n",
    "\n",
    "#### TODO: REWRITE PARA.  MOVE / REMOVE IF HAVE ALREADY HAD TO IMPORT EXTERNAL DATASETS BY THIS POINT IN THE TUTORIAL?</p>\n",
    "\n",
    "Working with built-in datasets is great for practice but for real-life work its vital that you can import our own data.\n",
    "Before we do this, we must learn where Python is expecting to find your files.\n",
    "It does this using the concept of the **present working directory**. \n",
    "\n",
    "To see what the current working directory is, we can use a function from the `os` package (which is always distributed with Python):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can list the contents of the directory with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create a new directory using the `mkdir` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.mkdir('mydata')\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move into this new directory using the `chdir` function, then view its contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir('mydata')\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current working directory is where Python is currently preferentially looking for files and also where it will put any files it creates unless you tell it otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing your own data\n",
    "\n",
    "#### TODO: REWRITE/MOVE/REMOVE SECTION\n",
    "\n",
    "In this section, you'll learn how to import data into Python from the common .csv (comma separated values) format.   \n",
    "\n",
    "#### TODO: already introduced\n",
    "\n",
    "Download the file [example_data.csv](https://raw.githubusercontent.com/mikecroucher/Code_cafe/master/First_steps_with_R/example_data.csv) to your current working directory. \n",
    "\n",
    "You can either do this manually, using your web browser, then run the following to load the data into a `pandas` DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "example_data = pd.read_csv('example_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or you can supply a URL as the first argument to the `read_csv` function from `pandas` to download and instantiate a DataFrame in a single step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "example_data = pd.read_csv('https://raw.githubusercontent.com/mikecroucher/Code_cafe/master/First_steps_with_R/example_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: `example_data`\n",
    "\n",
    "* Show the first few lines of `example_data`\n",
    "* Create a plot of the `example_data`\n",
    "* Show summary statistics of `example_data`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scripts\n",
    "\n",
    "#### TODO: REWRITE SECTION</p>\n",
    "\n",
    "In the simplest terms, a script is just a text file containing a list of R commands. We can run this list in order with a single command called `source()`\n",
    "\n",
    "An alternative way to think of a script is as a **permanent, repeatable, annotated, shareable, cross-platform archive**<sup>1</sup> of your analysis! Everything required to repeat your analysis is available in a single place. The only extra required ingredient is a computer.\n",
    "\n",
    "For example, based on the article at [http://www.walkingrandomly.com/?p=5254](http://www.walkingrandomly.com/?p=5254), we have created a script called `best_fit.R` that finds the parameters `p1` and `p2` such that the curve `p1*cos(p2*xdata) + p2*sin(p1*xdata)` is a best fit for the `example_data` described earlier. The details of this are beyond the scope of this course but you can easily download and run this analysis yourself.\n",
    "\n",
    "    download.file('https://raw.githubusercontent.com/mikecroucher/Code_cafe/master/First_steps_with_R/best_fit.R',destfile='best_fit.R')\n",
    "    source('best_fit.R')\n",
    "\n",
    "By doing this, you have reproduced the analysis that we did. You are able to check and extend our results or apply the code to your own work. Making code and data publicly  available like this is the foundation of [Open Data Science](http://opendsi.cc/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further reading and next steps\n",
    "\n",
    "In this session, we told you how to import data from a file but not how to export it. The following link will teach you how to export to `.csv`. [Tutorial: Exporting an R data frame to a .csv file](http://www.walkingrandomly.com/?p=5979) \n",
    "\n",
    "#### TODO: REMOVE/REPLACE THE ABOVE PARA\n",
    "\n",
    "There are many resources online and in print for learning Python.  Here are some recommendations:\n",
    "\n",
    "* Data Carpentry's introductory [*Python for Ecologists*](http://www.datacarpentry.org/python-ecology-lesson/) tutorial, which provide an introduction to using Python for automating data analysis tasks.\n",
    "* Software Carpentry's [*Programming with Python*](http://swcarpentry.github.io/python-novice-inflammation/) tutorial, which follows on from the Data Carpentry course and offers **FINISH**\n",
    "* The [*Dive Into Python 3*](http://www.diveintopython3.net/) by Mark Pilgrim.  Freely available online under a [CC-BY-SA license](https://creativecommons.org/licenses/by-sa/3.0/) and also published as a book by Apress (2009, ISBN: 978-1430224150).  Provides a introduction to Python as a general purpose programming language.  Each chapter starts with a block of (initially unreadable) code that supposedly does something useful; this is then picked apart to introduce the reader to different aspects of the language and its core libraries.\n",
    "* The [*Python for Data Analysis*](http://shop.oreilly.com/product/0636920023784.do) book by Wes McKinney (O’Reilly Media, 2012, ISBN: 978-1-4493-1979-3).  Wes is the original author of [pandas](pandas.pydata.org/), one of the most popular and powerful Python libraries for manipulating tabular data; this book focusses on\n",
    "* The [*Learn Python the Hard Way*](http://learnpythonthehardway.org/) book by Zed Shaw (3rd ed, Addison Wesley, 2013, ISBN: 978-0321884916).  Another book on Python as a general purpose language.  Readers can view the book online before they buy. \n",
    "\n",
    "#### TODO: PYTHON EQUIV OF SWIRL (`swirlypy`)?\n",
    "#### TODO: PROJECT EULER?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting help NOTES\n",
    "\n",
    "#### TODO: MERGE WITH EARLIER 'GETTING HELP SECTION'\n",
    "\n",
    "* TAB COMPLETION IN JUPYTER (DOES NOT WORK ON INDEXED OBJECTS e.g. `my_list[0].<tab>` OR OBJECTS THAT HAVE NOT YET BEEN INSTANTIATED)\n",
    "* ONLINE DOCS (e.g. [for numpy](http://docs.scipy.org/doc/numpy/)) OR DOCS IN IDE\n",
    "* [STACK OVERFLOW](http://stackoverflow.com/questions/tagged/python)\n",
    "* MAIL LISTS: pydata, pystatsmodels, numpy, scipy, matplotlib\n",
    "* IRC\n",
    "* Sheffield Python group\n",
    "\n",
    "#### TODO: FINISH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "#### TODO: remove/replace\n",
    "\n",
    "[1] [Getting Started with R - An Introduction for Biologists](https://global.oup.com/academic/product/getting-started-with-r-9780199601622?cc=gb&lang=en&). Authors: Beckerman and Petchey.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
