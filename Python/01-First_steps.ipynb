{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[# Introduction to Python for Data science: First steps\n",
    "[\n",
    "This is designed to be a self-directed study session where you work through the material at your own pace. If you are at a Code Cafe event, instructors will be on hand to help you.\n",
    "\n",
    "If you haven't done so already please read through the **[Introduction](./00-Introduction.ipynb)** to this course, which covers:\n",
    "\n",
    "1. **What Python is** and **why it is of interest**;\n",
    "1. **Learning outcomes** for the course; \n",
    "1. The course **structure** and **support facilities**;\n",
    "1. An introduction to **Jupyter Notebooks**;\n",
    "1. Information on course **exercises**.\n",
    "\n",
    "It will be useful to keep the **Introduction** material open in a separate tab whilst working on this session.\n",
    "\n",
    "<!-- * [Lesson setup code](#Lesson-setup-code) -->\n",
    "* [Simple commands and calculations](#Simple-commands-and-calculations)\n",
    "* [Using maths functions from the numpy Python package](#Using-maths-functions-the-numpy-Python-package)\n",
    "* [Functions with named and optional arguments](#Functions-with-named-and-optional-arguments)\n",
    "* [Getting help](#Getting-help)\n",
    "* [Variables](#Variables)\n",
    "\n",
    "\n",
    "* [Loading data: numpy and pandas](#Loading-data:-numpy-and-pandas)\n",
    "* [Querying tabular data stored in Numpy ndarrays](#Querying-tabular-data-stored-in-Numpy-n-dimensional-ndarrays)\n",
    "* [Extracting single values from numpy ndarrays](#Extracting-single-values-from-numpy-ndarrays)\n",
    "* [Extracting ranges from numpy ndarrays](#Extracting-ranges-inc.-entire-rows-and-columns-from-numpy-ndarrays)\n",
    "* [Missing data and statistical summaries](#Missing-data-and-statistical-summaries)\n",
    "\n",
    "\n",
    "* [Plotting data](#Plotting-data)\n",
    "* [Packages](#Packages)\n",
    "* [The current working directory](#The-current-working-directory)\n",
    "* [Importing your own data](#Importing-your-own-data)\n",
    "* [Scripts](#Scripts)\n",
    "* [Further reading and next steps](#Further-reading-and-next-steps)\n",
    "* [Getting help NOTES](#Getting-help-NOTES)\n",
    "* [References](#References)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson setup code\n",
    "\n",
    "Run the following Notebook cell *every time* you load this lesson (*but do not edit it*).  Don't be concerned with what this code does at this stage. \n",
    "\n",
    "**TODO: ENSURE NUMPY ALREADY INSTALLED AND AVAILABLE BY THIS POINT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "____ = 0\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy.testing import assert_almost_equal, assert_array_equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple commands and calculations\n",
    "\n",
    "Python is a command based system which means that you (usually) interact with it by entering commands rather than using a Graphical User Interface (GUI). Some of these commands are rather straightforward! For example, Python can be used to do arithmetic.  Run each cell in turn to evaluate the following expressions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "1 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "3 * 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "377 / 120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Power terms can be expressed using the `**` *operator* e.g. for $2^8$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "2 ** 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more complex expressions remember that some mathematical operations are [preferentially evaluated before others](https://en.wikipedia.org/wiki/Order_of_operations#Definition).\n",
    "\n",
    "Parentheses can be used to override that order of evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "31 * (365 - 30) / 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using maths functions from the `numpy` Python package\n",
    "\n",
    "As shown, support for basic arithmetic is built into Python itself but for other operations such as *sin*, *cos* and *log* we need to **import functions** for performing these operations from a Python **package**. A package is a collection of useful bits of code that we can reuse in many different programs.  Some packages come with Python itself, whilst others must be installed separately. \n",
    "\n",
    "Here we **import** the `numpy` package and use a **function** provided by the package to calculate the square root of `2`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.sqrt(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(*Keen-eyed readers will notice that we previously executed the `import...` line above back in the first code cell in this Notebook.  It doesn't do any harm to repeat this here.*)\n",
    "\n",
    "This is the first time we've entered a **function** in Python so let's discuss some details. In the above, \n",
    "\n",
    "* the **function name** is `sqrt`, \n",
    "* the function is from the **`numpy` package** (here aliased as `np` for convenience) and\n",
    "* here the function is **called** (**evaluated**) with an **argument** of 2.  Function arguments are always enclosed in parentheses.\n",
    "\n",
    "The terms **call**, **evaluate** and **argument** are oft-used by programmers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python is **case sensitive**. For example, a valid function call is `np.sqrt(2)` with everything in lower case. Variations such as `np.Sqrt(2)` or `np.SQRT(2)` won't work (**try it in a new code cell below**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `numpy` package also provides the standard trigonometry functions such as `sin`, `cos` and `tan`. These take their arguments in radians rather than degrees. As such, a right angle is  `pi/2` rather than 90. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sin(np.pi / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we didn't need to `import` `numpy` again; we only need to do so once per interactive IPython session.\n",
    "\n",
    "`numpy`'s `log` function takes the natural logarithm by default:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.log(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to calculate a logarithm to base 10, you need to use the `np.log10` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "As water flows thorugh a drinking water pipe under pressure it looses energy (pressure) due to friction at the pipe wall.  This can be quantified using the following equation (the [Swameeâ€“Jain approximation of the Colebrook White formula](https://en.wikipedia.org/wiki/Darcy_friction_factor_formulae#Swamee.E2.80.93Jain_equation), but you don't need to know anything about this):\n",
    "\n",
    "$$f = 0.25 \\left(\\log_{10} \\left(\\frac{k_s}{3.7D} + \\frac{5.74}{\\mathrm{Re}^{0.9}}\\right)\\right)^{-2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace '`____`' below with some Python that calculates a value for $f$ (the *'friction factor'*) using \n",
    "\n",
    "* $D = 0.075$ (the pipe diameter in metres)\n",
    "* $k_s = 0.005$ (the pipe wall 'roughness' in metres)\n",
    "* $Re = 4000$ (the 'Reynolds number' - a measure of the amount of turbulence)\n",
    "\n",
    "See the course **Introduction** section for more information on `assert`ing that you've got the correct answer to an exercise.  Also, **if you get stuck** then follow the link above regarding Python's *order of operations* to check that you know which operations will be done first and where you might need parentheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert_almost_equal(____, 0.08948259, decimal=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions with named and optional arguments\n",
    "\n",
    "The functions we have seen so far only take one argument but others take two or more arguments. For example, you can round a decimal number to zero decimal places like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "round(1.23456)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively you can round to a different number of decimal places by supplying a second argument when calling the `round` function.  Arguments are separated by commas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "round(1.23456, ndigits=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows another feature of Python functions: **named arguments**.\n",
    "\n",
    "Here, the function is calle using *two arguments*, with the second being associated with the `ndigits` **parameter**.  A parameter is (in simple terms) the **name of a function input** (e.g. the name `ndigits`), whereas an argument is the **value** sent to the function (e.g. the number `3`).  \n",
    "\n",
    "Since the second argument to `round` is, by design, always the number of decimals you could have simply executed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "round(1.23456, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but the named argument version is more readable.  Also, note that a value does not always need to be given for `ndigits` as it has a default value of `0`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting help\n",
    "\n",
    "Built in to Python itself and the packages you `import` is a large amount of documentation that you can call on any time.\n",
    "\n",
    "Firstly, if you forget the names and order of the `round` function's arguments you can ask Jupyter+IPython to display information about the function in a separate pane by calling the function with `?` instead of parentheses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "round?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly, you can see a more **terse pop-up summary** of a function by placing the cursor within `round` then press < Shift >< Tab >  **Try this**\n",
    "\n",
    "Thirdly, if you forget the name of a function or how to spell it you can type part of the name then press < tab > to **autocomplete** it (functionality sometimes known as **tab completion**).\n",
    "\n",
    "For example, if you can't remember whether the `numpy` function for randomly generating a number is called `random` or `rand`, try typing `np.ran` then press < tab >.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.ran"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case the function name is not immediately autocompleted as the entered characters are ambiguous: two functions start with `ran`.  Select the one you want from the drop-down menu that appears after pressing < tab >\n",
    "\n",
    "Fourthly, see the **Help** menu at the top of the Jupyter interface for links to the full reference documentation for Python, numpy and several other popular Python data science packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables\n",
    "\n",
    "We'll rarely want to perform a calculation and throw away the result. \n",
    "It is much more likely that we'll want to store the result in Python's memory for later use, \n",
    "either as part of future calculations or ready for export to external files.\n",
    "\n",
    "We do this by **assigning** the results of calculations to **variables**.  For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.sin(1)\n",
    "b = 10\n",
    "c = a + b\n",
    "c = c / 2\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, we created three variables called `a`, `b` and `c`.  With each line (starting with the first), the expression on the *right-hand side* of the `=` sign is evaluated (by calling functions and/or performing arithmetic to generate a single value), then the result is **assigned** to the variable on the left-hand side.  \n",
    "\n",
    "After assigning a value to a variable, the variable can be \n",
    " \n",
    "* used when evaluating subsequent expressions;\n",
    "* updated/reassigned to new values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can list the names of the variables that currently exist in this interactive IPython session using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%who"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these are variables you have created; others are variables that were created in the [Notebook setup cell above](#Lesson-setup-code).\n",
    "\n",
    "To see the value of any given variable, just execute a Notebook cell where the last line is just the variable name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = c + 5\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also view a summary of the names **and values** of all variables currently defined in your interactive IPython session using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The middle column above shows the **data type** of each variable.  This **denotes (and limits) the operations that can be applied to a given variable** (such as `c`) **or a literal value** (such as the number `1.23456`).  The data types you will most frequently encounter include:\n",
    "\n",
    "* `int`: integers a.k.a. whole numbers e.g. `6`\n",
    "* `float`: decimal numbers e.g `6.3`.  You will also encounter `float64` and possibly `float32` (both provided by the `numpy` package)\n",
    "* `str`: strings of characters e.g. `\"Subject A\"` or `'Sheffield, S1 3JD'`\n",
    "* `bool`: a [boolean](https://en.wikipedia.org/wiki/Boolean_data_type) value i.e. `True` or `False`\n",
    "\n",
    "We will revisit the idea of data types at a later stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, suppose that after defining a variable we now want to remove it from Python's memory.  We need execute a `del` statement e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Action**: list all currently-defined variables to prove that `c` no longer exists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to delete **all** currently-defined variables in an IPython session we can select *Kernel* -> *Restart* from the Jupyter Notebook menu bar or altenatively run a cell that contains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data: `numpy` and `pandas`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now jump in to looking at using Python for doing something useful: exploring some air quality data.\n",
    "\n",
    "Other languages such as R come with example datasets to allow us to quickly begin experimenting with data analysis techniques and plotting tools.  This is not the case with Python.  However, this is not an issue as the `numpy` and `pandas` packages provide functions for loading datasets from many different sources.\n",
    "\n",
    "[`pandas`](http://pandas.pydata.org/) allows us to load (typically tabular) data from:\n",
    "\n",
    "* Excel spreadsheets\n",
    "* [Comma-separated value](https://en.wikipedia.org/wiki/Comma-separated_values) (CSV) files \n",
    "* [Relational databases](https://en.wikipedia.org/wiki/Relational_database) (e.g. [PostgreSQL](https://www.postgresql.org/about/)).\n",
    "* Several other formats\n",
    "\n",
    "`numpy` allows us to load data from:\n",
    "\n",
    "* [Comma-separated value](https://en.wikipedia.org/wiki/Comma-separated_values) (CSV) files \n",
    "* Efficient binary-format files\n",
    "\n",
    "<!--We're going to load and explore [Fisher's Iris data](https://en.wikipedia.org/wiki/Iris_flower_data_set), which is often used to demonstrate statistical and [machine learning](https://en.wikipedia.org/wiki/Machine_learning) algorithms.\n",
    "\n",
    "The functionality offered by `pandas` for loading data is far more powerful and flexible than that offered by `numpy` but we are going to start by exploring `numpy` as it is simpler and learning about `pandas` later on should then be easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we are going to load and explore to help us learn the basics of `numpy` is from a weather station that is situated very near the University on Devonshire Green in Sheffield.  See [this page](https://uk-air.defra.gov.uk/networks/site-info?site_id=SHDG) on the UK Department for Environment, Food and Rural Affairs' site for a map and photos of the site.  Many environmental parameters such as air quality, temperature and wind speed are recorded at this site on a regular basis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're wanting to load a table of historic data captured at this weather station.  The data is stored in \n",
    "\n",
    "```bash\n",
    "Weather_data/Devonshire_Green_meteorological_data-preproc.csv\n",
    "```\n",
    "\n",
    "(*The associated metadata is in `Devonshire_Green_meteorological_metadata-preproc.json`; only provided for interest*).\n",
    "\n",
    "Let's crudely print out the first four lines of the file.  You do not have to understand the following; it is just to show you the format of the file.  *However*, be aware that this does not load the data from the file in a meaningful way; it simply and dumbly prints out lines of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_dir = 'Weather_data'\n",
    "csv_path = os.path.join(data_dir, 'Devonshire_Green_meteorological_data-preproc.csv')\n",
    "\n",
    "with open(csv_path, 'r') as csv_file:\n",
    "    for (line_num, line) in enumerate(csv_file):\n",
    "        if line_num >= 4: \n",
    "            break\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will see that \n",
    "\n",
    " * The first row of the file is column headings;\n",
    " * Columns are separated by commas;\n",
    " * Rows 2-4 contain a set of measurements taken at a specified time;\n",
    " * All lines have the same number of columns.\n",
    " \n",
    "Let's load that file in Python in a way that recognises the format of the data (headings and data arranged in columns):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dev_green = np.genfromtxt(csv_path, \n",
    "                          delimiter=',', \n",
    "                          skip_header=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try explaining these two lines of code to yourself in terms of functions, arguments and assignments.  Also, what do you think the purpose of `delimiter` and `skip_header` are?**  Don't worry if you cannot answer the second of those questions just yet and don't worry about exactly what `genfromtxt` does: that will become clear shortly.\n",
    "\n",
    "Note that here we have **split a single long statement over two lines** to make the code easier to read.  You can split a statement over multiple lines like this if you introduce line breaks between a pair of parentheses.  Alternatively, if you want to split a line outside of any parentheses you must include a backslash (\\\\) at the end of all but the last line to tell Python that the line is to be continued e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z = 45 + \\\n",
    "    36 + \\\n",
    "    27"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying tabular data stored in Numpy n-dimensional arrays (`ndarray`s)\n",
    "\n",
    "So, what has been assigned to the `dev_green` variable?  What have we created?  Let's ask IPython to generate a preview of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dev_green"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's not a single number but a **matrix** of numbers (written in [scientific notation](https://en.wikipedia.org/wiki/Scientific_notation)) with many rows and columns.\n",
    "\n",
    "More formally, this is a `numpy` **`ndarray`**, this being an **$n$-dimensional array** of values.\n",
    "For us $n$=2 i.e. `dev_green` is a 2D matrix.\n",
    "The '`...`' indicate that the matrix contains more rows and columns than have been displayed.\n",
    "\n",
    "#### Exercise\n",
    "\n",
    "How big is our dataset?  You can determine the number of rows and columns of `dev_green` by **passing** that **ndarray variable** as a single **argument** to the **`np.shape` function**.  Fill in the blank below to make the assert statement valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert(____ == (8760, 17))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `shape` function has returned not one but two numbers: <!-- (packaged together in a simple *data structure* called `tuple`; these will be covered later on).-->\n",
    "\n",
    "1. the **number of rows** (8760): here the number of (hopefully distinct) times at which sets of measurements were taken;\n",
    "1. the **number of columns** (17): here the number of columns required to represent the measurement time (4 columns) plus the number of different measurements that could be taken at each moment in time (13 columns).\n",
    "\n",
    "`ndarray`s **must always be rectangular**.  Another requirement is that every element in an `ndarray` must have the **same data type** e.g. every value must be an integer or every value must be a 'float' (decimal).\n",
    "\n",
    "We can also quickly determine the number of elements in an `ndarray` using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.size(dev_green)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting single values from `numpy` `ndarray`s\n",
    "\n",
    "We can view both **single elements** and also 1D or 2D **slices** of our `ndarray` using expressions that look like this:\n",
    "\n",
    "```python\n",
    "some_array[row_selector, column_selector]\n",
    "```\n",
    "\n",
    "How this works in practise should become clear after seing some examples.  To view just a single element:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dev_green[0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are extracting the value in the first row and first column of the `ndarray` i.e. the `ndarray` element with a **row index** of 0 and a **column index** of 0.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important**: Python, like many other programming languages, counts collections of values **starting from an index of 0**, *not* 1.  Therefore, if we have a one-dimensional array with 100 elements then the first and last elements have indexes of 0 and 99 respectively.  Note that Python's most direct competitors in the data science world, R and MATLAB, both count collections starting from an index of 1, not 0!\n",
    "\n",
    "You can therefore access the third element in the fifth column of the `dev_green` `ndarray` using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dev_green[2, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "What is the Modelled Wind Speed for the 418th measurement in the dataset?  \n",
    "\n",
    "*Hint: Svefg qrgrezvar gur ebj vaqrk hfvat vasbezngvba va gur dhrfgvba.  Arkg, qrgrezvar gur pbyhza vaqrk hfvat gur pbyhza urnqvatf fubja nf bhgchg sebz n cerivbhf pryy*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert_almost_equal(____, 4.2, decimal=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we access the **last value** in the first column?  The simplest way is like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dev_green[-1, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, an index of `-1` gives us the last element in a particular row or column.  An index of `-2` would give us the second-to-last element etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting ranges inc. entire rows and columns from `numpy` `ndarray`s\n",
    "\n",
    "If we want to **extract muliple values** from a ndarray we can specify an **index range** e.g. the first four values in the fifth column (ozone level) can be extracted with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dev_green[0:4, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The number before '`:`' is the index of the first element we are interested in.  \n",
    "    * If this is omitted then the range starts from the beginning of the row or column.\n",
    "* The number after '`:`' is the first index **after** the range of elements we want.\n",
    "    * If this is omitted then the range contiues to the end of the row or column.\n",
    "\n",
    "#### Exercise\n",
    "\n",
    "Here is a much simpler 1D `ndarray`.  Each element is a string of characters rather than a `float` (decimal number):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "interviewees = np.array([\"Albertha\", \"Aurora\", \"Collin\", \"Cris\", \"Genoveva\", \"Joanne\", \n",
    "                         \"Kamilah\", \"Katerine\", \"Lida\", \"Malcom\", \"Max\", \"Saundra\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use an index range to make the following `assert`ion statements valid.  Note that 1D ndarrays are indexed using  `some_array[selector]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert_array_equal(____, np.array([\"Genoveva\"]))\n",
    "assert_array_equal(____, np.array([\"Albertha\", \"Aurora\", \"Collin\"]))\n",
    "assert_array_equal(____, np.array([\"Malcom\", \"Max\"]))\n",
    "assert_array_equal(____, np.array([\"Max\", \"Saundra\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "To view an entire row, select all elements in a specific dimension using '`:`'.   Here is the earliest set of measurements in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dev_green[0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value returned by this indexing operation appears to be an `ndarray`.\n",
    "\n",
    "Notice that numpy has displayed every value using [scientific notation](https://en.wikipedia.org/wiki/Scientific_notation).  We can disable this for values that can easily be displayed without scientific notation using `numpy`'s `set_printoptions` function:\n",
    "\n",
    "# **TODO: EXPLAIN VIEWS VS COPY AND HOW TO CHECK W/ `arr[...].base is arr`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "dev_green[0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returning to our **indexing** and slicing, we can extract the **entire first column** (the year each measurement was taken) using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dev_green[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(Ignore the fact that this column has been output as a row for now.)*  \n",
    "\n",
    "We can confirm that this is an single column of the expected length using the `np.shape` function seen before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.shape(dev_green[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also extract 2D portions of our `ndarray` using index ranges.  \n",
    "\n",
    "For example, we can combine what we have learned so far to view the last five rows and first four columns of `dev_green`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dev_green[-5:, :4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we did not use `dev_green[-5:-1, :4]` as then we would have only have selected up to *but not including* the last element."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One final tip before we move on from slicing numpy arrays for now.\n",
    "The `a:b` range notation selects ranges of ajacent rows or columns.\n",
    "If we want to select rows or columns at **other regular intervals** then we use a range notation of the form `a:b:c` where `c` is our index increment between chosen elements. \n",
    "\n",
    "For example, to select the *year*, *month*, *day* and *hour* for only *even* rows in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dev_green[::2, :4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "whereas to select only *odd* rows in a certain *index range*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dev_green[1:12:2, :4]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Advanced indexing\n",
    "\n",
    "We have seen how we can extract portions of an `ndarray` when using:\n",
    "\n",
    "* single index values e.g `my_2d_array[5, 3]`;\n",
    "* a range of index values, possibly with e.g `my_2d_array[10:500:5, 3]` or `my_2d_array[275:300, -5:]`\n",
    "\n",
    "There are two other key ways of indexing `ndarray`s that we need to know about.\n",
    "\n",
    "### Indexing with a boolean sequence \n",
    "\n",
    "\n",
    "\n",
    "### Indexing with an integer sequence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Plotting data and comments\n",
    "\n",
    "## DEPENDENCIES: ADVANCED INDEXING, MISSING DATA\n",
    "\n",
    "# Knowing how to extract portions of our dataset and is essential for creating \n",
    "# visual plots of our data.  Some plots we may want to produce include:\n",
    "#  - a histogram showing the distribution of a particular variable (column)\n",
    "#  - a scatter plot showing the distribution of two variables (i.e. how they *covary*)\n",
    "#  - a line plot showing how a variable changes over time\n",
    "\n",
    "#In Python plots are typically created using the versatile and powerful\n",
    "# [Matplotlib](http://matplotlib.org/) library.  Other libraries also offer \n",
    "# plotting functionality but these often use Matplotlib behind the scenes.\n",
    "\n",
    "# Here's how we can create a histogram of Ozone concentration:\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1)\n",
    "axes.hist(dev_green[~np.isnan(dev_green[:, 4]), 4])\n",
    "\n",
    "# The **X** lines of code above do the following:\n",
    "\n",
    "# 1. Import the (necessary part of) the matplotlib package.\n",
    "# 1. Tell Matplotlib to use a particular theme (colours and line styles)\n",
    "# 1. Instruct `matplotlib` and `IPython` to display plots in the Notebook\n",
    "#    between cells rather than in an external window\n",
    "# 1. Create a new `Figure` (plot window) called `fig` \n",
    "#    containing a single Axes (subplot) object called `axes`.  \n",
    "#    WILL SEE OTHER WAYS OF CREATING PLOTS; THIS ONE NICE AS \n",
    "#    CAN ALSO USE FOR CREATING GRIDS OF SUBPLOTS IF INCREASE nrows/ncols.\n",
    "#    MULTIPLE ASSIGNMENT - EXPLAINED BEFORE?\n",
    "# 1. ONLY MANDATORY ARGUMENT TO HIST IS A NDARRAY THAT DOES NOT CONTAIN NANS \n",
    "#    (ALREADY MENTIONED?)\n",
    "#    MUST FILTER DEV_GREEN OZONE COLUMN TO JUST NON-NAN VALUES (ALREADY COVERED?)\n",
    "#    NOTE THAT USING METHOD HERE (EXPLAIN LATER?) AND CAN USE TAB COMPLETION \n",
    "\n",
    "# WE CAN MAKE PLOT MORE USEFUL AND ATTRACTIVE WITH FEW REFINEMENTS.  \n",
    "\n",
    "# # USE PLOT STYLE THAT LOOKS BETTER ON SCREEN\n",
    "# plt.style.use('ggplot')\n",
    "#\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1)\n",
    " \n",
    "axes.hist(dev_green[~np.isnan(dev_green[:, 4]), 4], bins=30)\n",
    "# Set the title\n",
    "axes.set_title('Distribution of Ozone at Devonshire Green weather station')\n",
    "# Set the x and y axis labels\n",
    "axes.set_xlabel('Concentration (micrograms per cubic m)')\n",
    "axes.set_ylabel('Number of samples')\n",
    "\n",
    "\n",
    "# The above code cell contains several *comments**.  \n",
    "# In Python, any characters to the right of a hash (`#`) sign \n",
    "# (unless #`# is in quotes) are comments ignored by the Python intepreter \n",
    "# (the mechanism that interprets and executes the code).  \n",
    "# Comments are a valuable means for reminding you and/or others how the software works\n",
    "# and why it was implemented in a particular way.\n",
    "# You should get in the habit of using comments throughout your code \n",
    "# (either inline after `#` characters or, if using Jupyter Notebooks, in text cells). \n",
    "#\n",
    "# **Tip:** write comments that would help you regain an understanding of your code\n",
    "# were you revisit it after a period of three months.\n",
    "\n",
    "# SCATTER PLOT\n",
    "\n",
    "# NEED TO REMOVE NANS AGAIN?\n",
    "# WHICH METHOD MOST ELEGANT BUT ALSO IN KEEPING WITH WHAT PRESENTED SO FAR?\n",
    "\n",
    "## LINE PLOT\n",
    "#\n",
    "# NANS NOT MATTER HERE?\n",
    "# WHICH SERIES MOST INTERESTING?  TEMPERATURE?\n",
    "\n",
    "# LOOPING (USING LINE PLOTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing data and statistical summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we can extract different portions of our dataset we'd like to be able to calculate some summary statistics.  For example, the mean `Ozone` level over the first five measurement times is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(dev_green[:5, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we encounter a problem when we try to find the mean of *all* the values in the last column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(dev_green[:, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is this `nan` value that the `mean` function returned?  It is an abbreviation for **'not a number'** and serves two purposes.\n",
    "\n",
    "1. It is the value returned when an operation evaluates to something that **mathematical is undefined** (**test this** with `np.log(-1)`);\n",
    "1. It can also indicate **missing values** in a dataset (e.g. values corresponding to times when a sensor was not functioning correctly).  \n",
    "\n",
    "The second case is the one we've encountered here: if we look at our CSV file we can see it contains some lines where there are no values between our column delimiters (commas).  Here's an example of a line with missing values \n",
    "(don't worry if you don't understand the code; just look at the output);\n",
    "these missing values are interpretted as `nan` when we read in the file using the `genfromtxt` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(csv_path, 'r') as csv_file:\n",
    "    for line in csv_file:\n",
    "        if ',,' in line:\n",
    "            print(line)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore how to identify and deal with missing values in `ndarrays` using a very simple dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lap_times = np.array([10.973, 25.152, np.NaN, 19.826,\n",
    "                      19.312, 25.979, 17.147, 31.737,\n",
    "                      np.NaN, np.NaN, 14.449, 11.135])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To count the number of missing values (a trivial task here but automation is necessary for larger datasets) we can use the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sum(np.isnan(lap_times))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happening here?  Let's break it down into steps, starting with the middle:\n",
    "\n",
    "1) Determine whether each element is NaN or not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.isnan(lap_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function returns a `ndarray` of same shape as its input where each element is `True` if the corresponding element in `lap_times` is `NaN` and `False` otherwise.  \n",
    "\n",
    "2) Pass this **boolean** (True/False only) `ndarray` to `np.sum`.  This function adds all elements in this new ndarray, treating `True` values as `1` and `False` as `0`.  This is the standard behaviour when Python encounters boolean values in a numerical context such as an arithmetic expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "False + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "5 * True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we wanted to count the number of non-NaN values in the array?  We can use the '`~`' operator to negate the result of `np.isnan(lap_times)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "~np.isnan(lap_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sum(~np.isnan(lap_times))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, how many missing values do we have in our air quality dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sum(np.isnan(dev_green))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "What is this as a proportion of the dataset (accurate to at least 3 decimal places)?\n",
    "\n",
    "*Hint: Gur ac.fvmr shapgvba, zragvbarq cerivbhfyl, pbhyq or hfrshy urer*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert_almost_equal(____, 0.231, decimal=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to **count the missing values per row or per column**?  \n",
    "\n",
    "Above, `np.sum` counts True values in all rows and columns; however, we can request per-column counts using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sum(np.isnan(dev_green), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the only the first four columns don't contain missing values.  Note that you can replace `0` with `1` for per-row counts.  Many other functions also have an `axis` parameter that works in the same way.\n",
    "\n",
    "Now that we've learned more about the presence of missing data in our dataset let's return to the task of trying to **calculate some statistical summaries**.\n",
    "\n",
    "As seen above, `np.mean` will return `np.NaN` if *any* element of the `ndarray` passed as an argument is `np.NaN` i.e. **`np.mean` propagates `np.NaN` values**.  \n",
    "\n",
    "However, `numpy` provides a set of functions to complement `np.sum`, `np.mean`, `np.std` (standard deviation) that ignore missing values.  Their names all start with `nan`.\n",
    "\n",
    "#### Exercise\n",
    "\n",
    "Use `np.nanmean` to find the mean of each of the columns from the fourth column up to and including the last (whilst ignoring missing values).  \n",
    "\n",
    "*Hint: see the help for this function.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.nanmean("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Use tab completion (see [Getting help](#Getting-help) above) to see the other functions for which NaNs are removed rather than propagated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Calculate the median (correct to 3 decimal places) of the last 100 Ozone values in the dataset (Ozone is the 5th column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert_almost_equal(____, 54.083, decimal=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../seaborn-data/iris.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we loaded the data from the CSV into a `pandas` **`DataFrame`**, which is a table of data plus a **label** for each row and column.\n",
    "\n",
    "How big is this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that it has 150 rows (and 5 columns) we might not want to view it all at once but instead might just want to see the first few rows:\n",
    "\n",
    "<p class=\"n\"> TODO: explain that here we have a method of a DataFrame, not a function of a package (although both are expressed in the form `foo.bar`)?</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now see that each row corresponds to a flower sample and each column to a flower attribute.  Note the names above each column and index values to the left of each row.  Here those index values were not present in the raw data but were automaticaly added when we imported the CSV file.\n",
    "\n",
    "**TODO: Discuss dtypes?**\n",
    "\n",
    "We might also want to view a statistical summary of the dataset to learn of the mean and variance of each flower attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here `std` is the standard deviation and `25%` `50%` and `75%` are [percentiles](https://en.wikipedia.org/wiki/Percentile) of the data.\n",
    "Also, note that the summary is only of the columns that contain numerical data.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to extract just one column then we can wrap the column in single quotes and square brackets then append this to to the DataFrame name.  For example, we can calculate the median sepal length like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['sepal_length'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many unique species do we have in our dataset?\n",
    "\n",
    "<p class=\"n\">TODO: here `unique` return a numpy array of objects - explain 'noisy' output from Notebook cell?</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['species'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or more concisely:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['species'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting data\n",
    "\n",
    "<p class=\"n\">TODO: REWRITE SECTION</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"n\">TODO: DECIDE ON PLOTTING APPROACH</p>\n",
    "\n",
    "<p class=\"n\">1. INVOLVES LOOP + BLOCK (INDENTING), MULTIPLE ASSIGNMENT, GROUPBY.  +ve: FAIRLY COMPACT FORM.  AUTOMATIC TITLING AND AXIS LABELLING IS NICE.  -ve: POOR PREPARATION FOR PLOTTING USING NUMPY</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "for species_name, species_specific_df in df.groupby('species'):\n",
    "    species_specific_df.plot(kind='scatter', x='petal_length', y='petal_width', \n",
    "                             title=species_name);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"n\">OR</p>\n",
    "\n",
    "<p class=\"n\">2. Involves manual figure creation and indexing by boolean series.  +ve: transferrable to plotting with numpy; -ve: more verbose and manual</p>\n",
    "\n",
    "<p class=\"n\">TODO: Point out that using comments here and note the value in documenting code</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for each distinct species in our dataset\n",
    "for species in df['species'].unique():\n",
    "    # Isolate all samples of just that species and store the result in a new DataFrame\n",
    "    df_for_species = df[df['species'] == species]\n",
    "    \n",
    "    # Create a blank figure\n",
    "    plt.figure()\n",
    "    \n",
    "    # Create a scatter plot for petal length against width for the current species only\n",
    "    plt.scatter(df_for_species['petal_length'], df_for_species['petal_width'])\n",
    "    \n",
    "    # Add a species-specific title\n",
    "    plt.title(species)\n",
    "    \n",
    "    # Add x and y axis labels\n",
    "    plt.xlabel('Petal length')\n",
    "    plt.ylabel('Petal width')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"n\">or</p>\n",
    "\n",
    "<p class=\"n\">3. seaborn.  How pandas specific?  Better to get aquainted with matplotlib rather than mask away all the complexity?  Nice to have all data on one plot though</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "g = sns.FacetGrid(data=df, hue='species', size=6)\n",
    "g.map(plt.scatter, 'petal_width', 'petal_length')\n",
    "g.add_legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"n\">or</p>\n",
    "\n",
    "<p class=\"n\">4. Another approach with seaborn.  Same points apply</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.lmplot('petal_width', 'petal_length', data=df, hue='species', fit_reg=False, size=6);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: Anscome's quartet\n",
    "\n",
    "Try summarising and plotting a different dataset using the commands you've learned.  The dataset to investigate is [Anscombe's quartet](https://en.wikipedia.org/wiki/Anscombe%27s_quartet), the data for which can be found in the CSV file `../seaborn-data/anscombe.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages\n",
    "\n",
    "<p class=\"n\">TODO: REWRITE OR JUST REMOVE SECTION.</p>\n",
    "\n",
    "R has many functions built in but there are over [8000 freely available add-on packages](https://cran.r-project.org/web/packages/) that provide thousands more functions. Once you know the name of a package, you call install it very easily.\n",
    "\n",
    "For example, a package called [ggplot2](http://ggplot2.org/) is widely used to create high quality graphics.  To install ggplot2:\n",
    "\n",
    "    install.packages(\"ggplot2\")\n",
    "\n",
    "We make all of the `ggplot2` functions available to our R session with the `library` command\n",
    "\n",
    "    library(ggplot2)\n",
    "\n",
    "Among other things, this makes the [qplot](http://docs.ggplot2.org/0.9.3/qplot.html) function available to us. We can use this as an alternative to the basic `plot` command described above\n",
    "\n",
    "    qplot(iris$Petal.Length, iris$Petal.Width,col=iris$Species)\n",
    "\n",
    "Alternatively, we can save ourselves typing `iris$` a lot by telling `qplot` that the data we are referring to is the iris data\n",
    "\n",
    "    qplot(data=iris,Petal.Length, Petal.Width,col=Species)\n",
    "\n",
    "To get help about the functionality in the ggplot2 package:\n",
    "\n",
    "    help(package=ggplot2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise (Packages)\n",
    "\n",
    "<p class=\"n\">TODO: REWRITE/REPLACE.  NB can't install new packages on SageMathCloud</p>\n",
    "\n",
    "A very popular R package is [MASS](https://cran.r-project.org/web/packages/MASS/index.html) which was created to support the book [Modern Applied Statistics with S](http://www.springer.com/gb/book/9780387954578). This contains many more classic data sets which can be used to develop your R skills.\n",
    "\n",
    "1. Install the MASS package on your machine.\n",
    "2. Explore the MASS package's documentation and find a dataset that interests you.\n",
    "3. Load the MASS library into your R session.\n",
    "4. Take a look at the dataset you chose in part (2) using what you've learned so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The current working directory\n",
    "\n",
    "<p class=\"n\">TODO: REWRITE PARA.  MOVE / REMOVE IF HAVE ALREADY HAD TO IMPORT EXTERNAL DATASETS BY THIS POINT IN THE TUTORIAL?</p>\n",
    "\n",
    "Working with built-in datasets is great for practice but for real-life work its vital that you can import our own data.\n",
    "Before we do this, we must learn where Python is expecting to find your files.\n",
    "It does this using the concept of the **present working directory**. \n",
    "\n",
    "To see what the current working directory is, we can use a function from the `os` package (which is always distributed with Python):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can list the contents of the directory with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create a new directory using the `mkdir` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.mkdir('mydata')\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move into this new directory using the `chdir` function, then view its contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir('mydata')\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current working directory is where Python is currently preferentially looking for files and also where it will put any files it creates unless you tell it otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing your own data\n",
    "\n",
    "<p class=\"n\">TODO: REWRITE/MOVE/REMOVE SECTION.</p>\n",
    "\n",
    "In this section, you'll learn how to import data into Python from the common .csv (comma separated values) format.   <p class=\"n\">TODO: already introduced</p>\n",
    "\n",
    "Download the file [example_data.csv](https://raw.githubusercontent.com/mikecroucher/Code_cafe/master/First_steps_with_R/example_data.csv) to your current working directory. \n",
    "\n",
    "You can either do this manually, using your web browser, then run the following to load the data into a `pandas` DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "example_data = pd.read_csv('example_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or you can supply a URL as the first argument to the `read_csv` function from `pandas` to download and instantiate a DataFrame in a single step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "example_data = pd.read_csv('https://raw.githubusercontent.com/mikecroucher/Code_cafe/master/First_steps_with_R/example_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: `example_data`\n",
    "\n",
    "* Show the first few lines of `example_data`\n",
    "* Create a plot of the `example_data`\n",
    "* Show summary statistics of `example_data`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scripts\n",
    "\n",
    "<p class=\"n\">TODO: REWRITE SECTION</p>\n",
    "\n",
    "In the simplest terms, a script is just a text file containing a list of R commands. We can run this list in order with a single command called `source()`\n",
    "\n",
    "An alternative way to think of a script is as a **permanent, repeatable, annotated, shareable, cross-platform archive**<sup>1</sup> of your analysis! Everything required to repeat your analysis is available in a single place. The only extra required ingredient is a computer.\n",
    "\n",
    "For example, based on the article at [http://www.walkingrandomly.com/?p=5254](http://www.walkingrandomly.com/?p=5254), we have created a script called `best_fit.R` that finds the parameters `p1` and `p2` such that the curve `p1*cos(p2*xdata) + p2*sin(p1*xdata)` is a best fit for the `example_data` described earlier. The details of this are beyond the scope of this course but you can easily download and run this analysis yourself.\n",
    "\n",
    "    download.file('https://raw.githubusercontent.com/mikecroucher/Code_cafe/master/First_steps_with_R/best_fit.R',destfile='best_fit.R')\n",
    "    source('best_fit.R')\n",
    "\n",
    "By doing this, you have reproduced the analysis that we did. You are able to check and extend our results or apply the code to your own work. Making code and data publicly  available like this is the foundation of [Open Data Science](http://opendsi.cc/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further reading and next steps\n",
    "\n",
    "In this session, we told you how to import data from a file but not how to export it. The following link will teach you how to export to `.csv`. [Tutorial: Exporting an R data frame to a .csv file](http://www.walkingrandomly.com/?p=5979) <span class=\"n\">TODO: REMOVE/REPLACE</span> \n",
    "\n",
    "There are many resources online and in print for learning Python.  Here are some recommendations:\n",
    "\n",
    "* Data Carpentry's introductory [*Python for Ecologists*](http://www.datacarpentry.org/python-ecology-lesson/) tutorial, which provide an introduction to using Python for automating data analysis tasks.\n",
    "* Software Carpentry's [*Programming with Python*](http://swcarpentry.github.io/python-novice-inflammation/) tutorial, which follows on from the Data Carpentry course and offers **FINISH**\n",
    "* The [*Dive Into Python 3*](http://www.diveintopython3.net/) by Mark Pilgrim.  Freely available online under a [CC-BY-SA license](https://creativecommons.org/licenses/by-sa/3.0/) and also published as a book by Apress (2009, ISBN: 978-1430224150).  Provides a introduction to Python as a general purpose programming language.  Each chapter starts with a block of (initially unreadable) code that supposedly does something useful; this is then picked apart to introduce the reader to different aspects of the language and its core libraries.\n",
    "* The [*Python for Data Analysis*](http://shop.oreilly.com/product/0636920023784.do) book by Wes McKinney (Oâ€™Reilly Media, 2012, ISBN: 978-1-4493-1979-3).  Wes is the original author of [pandas](pandas.pydata.org/), one of the most popular and powerful Python libraries for manipulating tabular data; this book focusses on\n",
    "* The [*Learn Python the Hard Way*](http://learnpythonthehardway.org/) book by Zed Shaw (3rd ed, Addison Wesley, 2013, ISBN: 978-0321884916).  Another book on Python as a general purpose language.  Readers can view the book online before they buy. \n",
    "\n",
    "<p class=\"n\">TODO: PYTHON EQUIV OF SWIRL (`swirlypy`)?</p>\n",
    "<p class=\"n\">TODO: PROJECT EULER?</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting help NOTES\n",
    "\n",
    "<p class=\"n\">TODO: MERGE WITH EARLIER 'GETTING HELP SECTION'</p>\n",
    "\n",
    "* TAB COMPLETION IN JUPYTER (DOES NOT WORK ON INDEXED OBJECTS e.g. `my_list[0].<tab>` OR OBJECTS THAT HAVE NOT YET BEEN INSTANTIATED)\n",
    "* ONLINE DOCS (e.g. [for numpy](http://docs.scipy.org/doc/numpy/)) OR DOCS IN IDE\n",
    "* [STACK OVERFLOW](http://stackoverflow.com/questions/tagged/python)\n",
    "* MAIL LISTS: pydata, pystatsmodels, numpy, scipy, matplotlib\n",
    "* IRC\n",
    "* Sheffield Python group\n",
    "\n",
    "<p class=\"n\">TODO: FINISH</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] [Getting Started with R - An Introduction for Biologists](https://global.oup.com/academic/product/getting-started-with-r-9780199601622?cc=gb&lang=en&). Authors: Beckerman and Petchey.  <p class=\"n\">TODO: remove/replace</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
